\documentclass{beamer} %use [handout] to get summary]
\usepackage{pdfpages}
%\setbeameroption{show notes on second screen=left} %enable for notes
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{hyperref}
\lstset{language=R,frame=single}
\usepackage{verbatim}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{relsize}
\usepackage{appendixnumberbeamer}
\usepackage{xparse}
\usepackage{multimedia}
\usepackage{tikz}
\usetikzlibrary{matrix,backgrounds}
\pgfdeclarelayer{myback}
\pgfsetlayers{myback,background,main}

\tikzset{mycolor/.style = {line width=1bp,color=#1}}%
\tikzset{myfillcolor/.style = {draw,fill=#1}}%
\tikzstyle{line} = [draw, line width=1pt]
\tikzstyle{arrow} = [draw, line width=1pt, ->]

\NewDocumentCommand{\highlight}{O{blue!40} m m}{%
\draw[mycolor=#1,rounded corners] (#2.north west)rectangle (#3.south east);
}

\NewDocumentCommand{\fhighlight}{O{blue!40} m m}{%
\draw[myfillcolor=#1,rounded corners] (#2.north west)rectangle (#3.south east);
}

\usetheme[numbering=fraction]{metropolis}
%%\AtBeginSection[]
%%{
%%  \begin{frame}
%%    \frametitle{Table of Contents}
%%    \tableofcontents[currentsection]
%%  \end{frame}
%%}

%%\let\olditem\item
%%\renewcommand{\item}{\vspace{0.5\baselineskip}\olditem}

\newcommand{\E}[1]{\mathbb{E}\left[#1\right]}
\begin{document}

\title{Bootstrapping}
\subtitle{(and a bit more)}
\author{Andrew Lampinen}
\date{Psych 252, Winter 2019}
\frame{\titlepage}

\begin{frame}{Outline}
\vspace{1em}
\tableofcontents
\end{frame}

\begin{frame}[standout]
These slides contain bullet points that summarize the argument.
\end{frame}

\section{Why bootstrapping?}
\begin{frame}[standout]
Bootstrapping makes fewer assumptions than parametric methods. 
\end{frame}

\begin{frame}[label=heteroscedasticity]
\frametitle{Non-IID noise (heteroscedasticity)}
\only<6-7>{
What if the null is true?
}
\only<-7>{
\begin{figure}
\centering
\only<1>{
\includegraphics[width=\textwidth]{figures/error_dist_non_null.png}
}
\only<2>{
\includegraphics[width=\textwidth]{figures/heteroscedasticity_consequences.png}
}
\only<3>{
\includegraphics[width=\textwidth]{figures/what_does_that_mean.png}
}
\only<4>{
\includegraphics[width=\textwidth]{figures/error_dist_CI_example_parametric_only.png}
}
\only<5>{
\includegraphics[width=\textwidth]{figures/error_dist_CI_example.png}
}
\only<6>{
\includegraphics[width=\textwidth]{figures/error_dist_null.png}
}
\only<7>{
\includegraphics[width=\textwidth]{figures/error_dist_proportion_significant.png}
}
\end{figure}
}
\only<8->{
    \begin{itemize} \itemsep 1em
    \item Linear models assume IID noise.
    \item Therefore heteroscedasticity leads to incorrect confidence intervals \textbf{and} hypothesis tests.
    \item Bootstrapping avoids this assumption, and so behaves more appropriately if heteroscedasticity is present.
    \end{itemize}
}
\end{frame}

\begin{frame}[standout]
Bootstrapping makes fewer assumptions than parametric methods, so it works better when those assumptions don't hold. 
\end{frame}

\begin{frame}{A case study in weird tests}
\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figures/conceptual_density_plot.png}
\end{figure}
$$\text{Test statistic} = \frac{D_\text{KL}\left(P_1 || \frac{P_1 + P_2}{2}\right) + D_\text{KL}\left(P_2 || \frac{P_1 + P_2}{2}\right)}{2}$$
\end{frame}

\begin{frame}[standout]
Bootstrapping makes fewer assumptions than parametric methods, so it can be applied in cases where parametric sampling distributions aren't known. 
\end{frame}

\section{What is bootstrapping anyway?}

\begin{frame}[standout]
Fundamental idea: Your best (or only) estimate of what's happening in the population is what's happening in your sample. 
\end{frame}

\againframe<1>{heteroscedasticity}

\begin{frame}[standout]
So instead of making assumptions about the population, we'll use what we actually know from the sample.
\end{frame}

\begin{frame}{Bootstrap resampling}
\begin{itemize}[<+->] \itemsep 1em
\item We want to understand our uncertainty about a statistic we are estimating (e.g. a difference of means).
\item The correct (frequentist) way to do this would be to run many experiments, and see how much that parameter varies, but usually this is infeasible.
\item Instead, we assume our sample distribution closely approximates the population distribution.
\item Therefore we can \textbf{simulate} these repeated experiments by \textbf{resampling from our sample with replacement.}
\end{itemize}
\end{frame}

\begin{frame}[standout]
We'll estimate a sampling distribution for our statistic of interest by resampling (with replacement) from our experimental sample.
\end{frame}

\begin{frame}<1>[label=boot_resamp_I]
\frametitle<1>{Bootstrap resampling demo I}
\frametitle<2>{Bootstrap CI demo I}
\centering
\url{http://wise.cgu.edu/portfolio/bootstrapping/}
\end{frame}

\begin{frame}[label=boot_resamp_II]
\frametitle{Bootstrap resampling demo II}
\begin{figure}
\centering
\only<1>{
\includegraphics[width=\textwidth]{figures/bootstrap_demo_0.png}
}
\only<2>{
\includegraphics[width=\textwidth]{figures/bootstrap_demo_1.png}
}
\only<3>{
\includegraphics[width=\textwidth]{figures/bootstrap_demo_2.png}
}
\only<4>{
\includegraphics[width=\textwidth]{figures/bootstrap_demo_3.png}
}
\only<5>{
\includegraphics[width=\textwidth]{figures/bootstrap_demo_4.png}
}
\only<6>{
\includegraphics[width=\textwidth]{figures/bootstrap_demo_5.png}
}
\end{figure}
\end{frame}

\section{Bootstrap confidence intervals}

\begin{frame}[fragile]
\frametitle{Bootstrap confidence intervals}
A simple application:
\begin{itemize}[<+(1)->] \itemsep 1em
\item We compute a statistic (such as the mean) from some data, and want to understand our uncertainty about it.
\item Remember: The bootstrap idea is that we can \textbf{simulate} these repeated experiments by \textbf{resampling from our sample with replacement.}
\item Now, we'll use the sampling distribution that we ``observe'' in these ``experiments'' to construct a confidence interval.
\item The simplest method (``percentile'') just uses the 2.5\% and 97.5\% quantiles of the bootstrap sampling distribution as the CI endpoints. (This is what \verb!mean_cl_boot! does).
\end{itemize}
\end{frame}

\againframe<2>{boot_resamp_I}

\begin{frame}<1>[fragile, label=boot_CI_demo]
\frametitle{Bootstrap CI demo II}
\begin{figure}
\centering
\only<1>{
\includegraphics[width=\textwidth]{figures/bootstrap_CI_0.png}
}
\only<2>{
\includegraphics[width=\textwidth]{figures/bootstrap_CI_1.png}
}
\only<3>{
\includegraphics[width=\textwidth]{figures/bootstrap_CI_2.png}
}
\end{figure}
\end{frame}

\begin{frame}[standout]
To compute a bootstrap percentile CI, compute a bootstrap sampling distribution and take the 2.5\% and 97.5\% quantiles as the CI endpoints.
\end{frame}

\againframe<2->{boot_CI_demo}

\begin{frame}[standout]
Generally BCA intervals are superior. You can get them from the boot library in R!
\end{frame}

\againframe<1>{heteroscedasticity}
\againframe<6>{boot_resamp_II}
\againframe<5>{heteroscedasticity}

\section{Bootstrap (and permutation) tests}

\begin{frame}[standout]
Estimation is at least as important as testing! \\[1em]
... but sometimes we do need a test for reviewer \#2.
\end{frame}

\begin{frame}{Bootstrap hypothesis tests}
How can we use bootstrapping for hypothesis testing?
\begin{itemize}[<+(1)->]
\item Construct a bootstrap $1-\alpha$ confidence interval.
\item Reject the null if the null hypothesis value of the statistic isn't included in this CI.
\end{itemize}
\uncover<4-5>{
\includegraphics[width=\textwidth]{figures/bootstrap_test.png}
\begin{tikzpicture}[overlay, remember picture]
\only<4>{
\fill [bg] (5.25, 0) -- (5.25, 6) -- (10.8, 6) -- (10.8, 0);
}
\end{tikzpicture}
}
\end{frame}

\begin{frame}[standout]
Bootstrap hypothesis testing: reject the null if the null value isn't contained in the 95\%-CI.
\end{frame}

\begin{frame}{Bootstrap $p$-values}
How can we get a $p$-value? 
\begin{itemize}
\item Find $\alpha$ so that the null value is just at the edge of the $(1-\alpha)$ CI,
 and let $p = \alpha$.
\end{itemize}
\only<1>{
\includegraphics[width=\textwidth]{figures/bootstrap_test.png}
}
\only<2->{
\includegraphics[width=\textwidth]{figures/bootstrap_test_999.png}
}
\end{frame}

\begin{frame}[standout]
Bootstrap $p$-values: $p$ is the min $\alpha$ such that the null value isn't contained in the $(1-\alpha)$ CI.
\end{frame}

\begin{frame}{Bootstrap tests \& $p$-values: some food for thought}
There are some subtle conceptual issues here:
\begin{itemize}[<+(1)->]
\item In NHST, we calculate the sampling distribution \textbf{under the null}, and see whether \textbf{our observed statistic} is surprising.
\item Here, we calculate the (approximate) sampling distribution under the \textbf{(approximate) population distribution,} and see whether the \textbf{null value} is surprising.
\item In many cases (such as anytime the null is true, or if the assumptions of e.g. linear regression hold), bootstrap tests are \textbf{exactly} standard NHST (at least asymptotically).
\item More generally, the bootstrap testing procedure \textbf{is valid}, in the sense that it has the nominal false-positive rate, but the interpretation of the $p$-value is not standard.  
\end{itemize}
\end{frame}

\begin{frame}[standout]
Bootstrap $p$-values: conceptually tricky, but so are regular frequentist ones, and reviewers probably won't understand either well enough to argue with you. 
\end{frame}

\begin{frame}{Permutation tests}
\begin{itemize}[<+->] \itemsep 1.5em
\item Sometimes we \textbf{can} actually nonparametrically sample from the null.
\item In a two-sample t-test, the null is that the two groups really are samples from the same distribution. 
\item We can actually sample from the null by just shuffling the labels. 
\item (This also works more generally, e.g. if you want to test median differences rather than mean.) 
\item (I will now steal some slides from Tobi.) 
\end{itemize}
\end{frame}

{
\setbeamercolor{background canvas}{bg=}
\includepdf[pages=1-6]{permtests.pdf}
}

\begin{frame}[standout]
To run a permutation test on data from two groups, randomly shuffle the group labels many times to generate a null sampling distribution.
\end{frame}

\begin{frame}{Permutation test robustness demo}
\begin{figure}
\centering
\only<1>{
\includegraphics[width=\textwidth]{figures/log_normal_dists.png}
}
\only<2->{
\includegraphics[width=\textwidth]{figures/perm_test.png}
}
\end{figure}
\end{frame}

\begin{frame}[standout]
Permutation tests maintain more power if $t$-test assumptions are violated. \\[1em]
However, both tests benefit from normality, so you should still transform your data if that makes it more normal. 
\end{frame}

\section{Bootstrap power analyses}

\begin{frame}{Can we use bootstrapping to calculate power?}
\begin{itemize}[<+(1)->]
\item Yes, if you have pilot or prior experiment data.
\begin{itemize}
    \item Bootstrap resample your pilot data with a resample size of e.g. $n=50$.
    \item See how many times your desired test (which can be any type, including parametric tests!) comes out significant.
    \item Repeat with a different resample size (e.g. $n=100$). 
    \item Iterate until you reach a sample size that achieves the desired power.
\end{itemize}
\item This will again be more accurate than parametric power calculations when your data don't exactly match the assumed distribution in some way.
\end{itemize}

\end{frame}

\begin{frame}[standout]
To bootstrap a power calculation, run your test on many bootstrap resamples with different resample sizes, and choose the resample size that gives you the desired true positive rate.
\end{frame}


\section{Wrapping up}

\begin{frame}{A few notes and caveats}
\only<1-2>{
\begin{figure}
\only<1>{
\includegraphics[width=\textwidth]{figures/panacea.jpg}
}
\only<2>{
\includegraphics[width=\textwidth]{figures/panacea2.jpg}
}
\end{figure}
}
\only<3->{
\begin{itemize}[<+(2)->]
\item If you can make the data better through experiment design tweaks or data transformation, do that first (it can only improve things). 
\item Samples should not be ``too'' small ($\gtrsim 20$ points, otherwise you \textbf{need} stronger assumptions that probably will be most easily expressed in a parametric framework).  
\item Should compute many bootstrap resamples ($R \approx 1000$ at least, come on, it's the 21st century, modern laptops are more powerful than 20th century supercomputers).
\item Biased estimators can still cause problems.
\item Non-parametrics generally \textbf{do} assume independence, so still need to use mixed(/hierarchical) models, and bootstrapping within these models must respect their dependence structure.
\end{itemize}
}

\end{frame}

\begin{frame}{Summary}
\begin{itemize}
\item Your sample is a better description of what's going on in the population than whatever you would assume \textit{a priori}.
\item So we will approximate samples from the population by resampling with replacement from our sample.
\item Using these samples to produce a sampling distribution, we can compute more accurate estimates of important quantities:%
    \begin{itemize}
    \item Confidence intervals.
    \item Hypothesis tests.
    \item Power calculutations.
    \end{itemize}
\item These will generally correspond to the parametric versions when the assumptions of the parametric versions hold, but will be more robust when those assumptions are violated.
\item Nonparametrics aren't a panacea, but they help. 
\end{itemize}
\end{frame}

\begin{frame}{Further reading}
\begin{itemize}
\item The classic:
    \begin{itemize}
    \item An Introduction to the Bootstrap, Efron \& Tibshirani, 1993
    \end{itemize}
\item Bootstrap hypothesis testing 
    \begin{itemize}
    \item \url{https://core.ac.uk/download/pdf/6494364.pdf} 
    \end{itemize}
\item Permutation tests:
    \begin{itemize}
    \item \url{http://faculty.washington.edu/kenrice/sisg/SISG-08-06.pdf} 
    \end{itemize}
\item More advanced \& general: 
    \begin{itemize}
    \item All of Nonparametric Statistics, Larry Wasserstein, 2006 (available electronically through Stanford Libraries!)
    \end{itemize}
\item Wikipedia, stackexchange, as always.
\end{itemize}
\end{frame}

\end{document}
